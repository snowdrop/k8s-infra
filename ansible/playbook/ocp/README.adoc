= OCP on RHOS Ansible Playbooks
Snowdrop Team
:icons: font
:revdate: {docdate}
:toc: left
:toclevels: 3
:description: Deploying OCP on RHOS
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

== Introduction

[.lead]
This document describes the process to deploy an OCP cluster on a 
 RHOS infrastructure.

The installation process uses the _OpenShift Container Platform installer_ 
 obtained from https://mirror.openshift.com/.

[glossary]
== Terminology

Glossary of terms used.

[glossary]
OCP:: OpenShift Container Platform
RHCOS:: Red Hat Core OS
RHOSP:: Red Hat OpenStack Platform

== OCP On OpenStack

Playbooks to deploy and remove an OCP cluster to RHOS. 

.List of OCP RHOS playbooks
[cols="30%m,70%"]
|===
|Playbook File |Description

| ocp_openstack_install.yml
| Deploy an OCP cluster on RHOS.

| ocp_openstack_remove.yml
| Remove an OCP cluster on RHOS.

| ocp_openstack_info.yml
a| Print information from the deployed OCP cluster.

This playbook will print cluster information such as Console URL, kubeadmin password, ...

|===

== Preparing the deployment

The OCP installation process requires the use of the OCP 
 pull secret. This secret can be obained from https://console.redhat.com/openshift/install/pull-secret.

As part of the installation process this information will be added 
 to the `install-config.yaml` and used in the OCP installation 
 process.

.Sample OCP pull secret JSON
[source,json]
----
{
  "auths": {
    "cloud.openshift.com": {"auth": "wwwwwwwwww", "email": "antcosta@redhat.com"}
    ,"quay.io": {"auth": "xxxxxxxxxxxxx", "email": "janedoe@example.com"}
    ,"registry.connect.redhat.com": {"auth": "yyyyyyyyyyyyy", "email": "janedoe@example.com"}
    ,"registry.redhat.io": {"auth": "zzzzzzzzzzzzzzzzz", "email": "janedoe@example.com"}
  }
}
----

[NOTE]
====
The commands described hereafter use the `OCP_PULL_SECRET` environment 
 variable to pass the credentials to the playbook.
====

== Using a Bootstrap host

In the installation process the several files are downloaded, amongst 
 which is the OCP installer software and a RHCOS image. During the execution 
 of the OCP installer the downloaded RHCOS image must be uploaded into RHOSP. 
 Although the image is cached, locally, this part of the process takes an 
 amount of time that cannot be disregarded.

The default installation process uses the controller (`localhost`) as the 
 installation executor. This means all files are downloaded/uploaded to/from 
 the local workstation. This approach has several drawbacks such as having 
 to rely on the network infrastructure of the workstation being limited by 
 it's bandwith (:arrow_down icon:arrow_down[alt=download] and icon:upload[alt=upload]). 

To mitigate this problem the installation process can, and we suggest it is, 
 executed from a remote host, which might be a temporary host. This host will 
 be referred as the bootstrap host hereafter.

To be able to use a temporary boostrap host it must be created prior to the 
 execution of the installation process. The name of this RHOSP Host can be 
 any name although we recomend including the name of the cluster as prefix 
 and adding a suffix such as `-tmp-bootstrap-server`.

To create the boostrap host execute the RHOSP playbook created for that purpose.

.Sample execution of creating a bootstrap host.
[source,bash]
----
ansible-playbook ansible/playbook/openstack/openstack_vm_create_passwordstore.yml -e '{"openstack": {"vm": {"network": "provider_net_shared","image": "Fedora-Cloud-Base-37", "flavor": "m1.small"}}}' -e vm_name=ocp-xyz-tmp-bootstrap-server
----

After creating the bootstrap host execute the steps provided in the 
 <<deploy-ocp-on-rhos>> section. 

[NOTE]
====
The bootstrap server could be removed once the OCP cluster has been 
 created (optional).
====

// tag::deploy_ocp_on_rhos[]
[#deploy-ocp-on-rhos]
== Deploy OCP Cluster on RHOS

The deployment playbook supports the follow variable entries.

.Script options
[%header,cols="25%,75%"]
|===
| Variable | Description

| `ocp_bootstrap_host`

[.fuchsia]#string#

a| VM name for the bootstrap host. 

If defined the installation process will be performed not on the 
 `localhost` controller but on the identified VM.

| `ocp_cluster_name`

[.fuchsia]#string# / [.red]#required# 

a| Name to be assigned to the OCP cluster

[NOTE]
====
Will also be applied as prefix to all the RHOS VM instances created as well 
 as other RHOS resources.
====

| `ocp_root_directory`

[.fuchsia]#string# / [.red]#required# 

a| Root folder where for the installation. A new sub-folder with the 
 `ocp_cluster_name` name will be created and will serve as the 
 installation folder.

| `openshift_pull_secret`

[.fuchsia]#json# / [.red]#required# 

a| OCP pull secret for the user

| `openstack_flavor_control_plane`

[.fuchsia]#string#

a| Flavor to be used on the Control Plane hosts.

*Default => `ocp4.control`*

| `openstack_flavor_compute`

[.fuchsia]#string#

a| Flavor to be used on the Compute hosts.

*Default => `ocp4.compute`*

|===

Execute the playbook. Please note that this playbook uses `sudo` permission 
 to create several folders so the Ansible user must have `sudo` permission. 
 We're using the `-K` switch to ask for the `become` password which is only 
 required if the user as sudo permission with password. The folders created 
 will be associated (`uid:gid``) with the Ansible user used to connect to the 
 host.

.Explanation of the playbook parameter execution
[source]
----
ansible-playbook ansible/playbook/ocp/ocp_openstack_install.yml <1>
  -e ocp_root_directory=<2>
  -e ocp_cluster_name=<3>
  -e openshift_pull_secret=<4>
  -K <5>
----
<1> Playbook that implements the OCP deployment.
<2> Root directory for the installation.
<3> Name to be given to the cluster.
<4> OCP pull secret for the user.
<5> Ask for the become password.

.Command to execute the OCP deployment playbook
[source,bash]
----
ansible-playbook ansible/playbook/ocp/ocp_openstack_install.yml \
  -e ocp_root_directory=/opt/ocp \
  -e ocp_cluster_name=ocp-sdev \
  -e openshift_pull_secret=${OCP_PULL_SECRET} \
  -K
----

The playbook will result on the deployment of several RHOS VMs for control plane and worker nodes.

.Note on the RHOS VM flavors
[NOTE]
====
The RHOS flavors to be used on the VMs that will result on the OCP cluster are
defined by the `openstack_flavor_control_plane` and `openstack_flavor_compute` 
variables, having as default the values from the role defaults file.

.Ansible Role default flavor configuration
[source,yaml]
----
include::../../roles/ocp_cluster/defaults/main.yml[tag=rhos_default_flavors]
----

Instructions on how to obtain the list of available flavors is described on
 our link:../../../openstack/openstack-cli.adoc#flavors[OpenStack CLI README file].
====

The result of the deployment process is the following:

* OCP cluster deployed on RHOS instances as defined in the number and flavor of main and worker nodes
* RHOS instance that will serve as jump server to the OCP cluster
* Installation directory stored on the passwordstore and copied to the jump server
* OCP authentication information stored on the passwordstore
// end::deploy_ocp_on_rhos[]

[CAUTION]
====
At this point the _bootstrap server_, if used, is no longer required.

[.lead]
Check that the installation folder is safely stored both on the jump server as well as on the local passwordstore before removing it.
====

// tag::undeploy_ocp_on_rhos[]
== Undeploy OCP Cluster on RHOS

[WARNING]
====
For the removal process to be successfull the OCP installation directory 
(`installation_dir`) must be provided as it store information on the RHOS
objects associated to the project.
====

.Command to execute the OCP cluster removal playbook.
[source,bash]
----
ansible-playbook playbook/ocp/ocp_openstack_remove.yml \
  -e ocp_root_directory=/opt/ocp \
  -e ocp_cluster_name=/opt/ocp/openshift-data/
----
// end::undeploy_ocp_on_rhos[]

== Other OCP RHOS Playbooks

=== Get information from the OCP cluster

To collect information on the OCP cluster execute the 
 `ocp_openstack_info` playbook located at the `ansible/playbook/ocp/` 
 folder.


.Playbook parameters
[%header,cols="25%,75%"]
|===
| Variable | Description

| `ocp_root_directory`

[.fuchsia]#string# / [.red]#required# 

a| Root folder for the OCP installation.

Either define the `ocp_root_directory` and `ocp_cluster_name` variables 
 or the `installation_dir` one.

| `ocp_cluster_name`

[.fuchsia]#string# / [.red]#required# 

a| Name of the OCP cluster

Either define the `ocp_root_directory` and `ocp_cluster_name` variables 
 or the `installation_dir` one.

| `installation_dir`

[.fuchsia]#string#

a| Location of the installation directory.

Either define the `ocp_root_directory` and `ocp_cluster_name` variables 
 or the `installation_dir` one.


| `vm_name`

[.fuchsia]#string# / [.red]#required# 

a| Root folder where for the installation. A new sub-folder with the 
 `ocp_cluster_name` name will be created and will serve as the 
 installation folder.

|===

[source,bash]
----
ansible-playbook ansible/playbook/ocp/ocp_openstack_info.yml \
  -e ocp_root_directory=/opt/ocp \
  -e ocp_cluster_name=ocp-sdev \
  -e vm_name=ocp-sdev-zzzzz-jump-server -vv
----

